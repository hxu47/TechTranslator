{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef37075f-67ba-438f-b53d-59626c62e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.12/site-packages (1.37.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.37.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.1->boto3) (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.1.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.1->boto3) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers boto3 numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a505fb-92c8-4e8b-a94f-2d3dadc1051e",
   "metadata": {},
   "source": [
    "# Cell 1: Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdfb7f2-223b-4de4-841c-51aaaa8a0234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 20:38:11.692063: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import boto3\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Dependencies installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53250832-ecf0-475c-883f-ad557c833c35",
   "metadata": {},
   "source": [
    "# Cell 2: Upload to S3 Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798c5ff4-bd9e-49d6-a7a4-0df58a5a713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Uploaded r-squared to s3://tech-translator-s3-knowledge-base/concepts/r-squared.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing S3 bucket: tech-translator-s3-knowledge-base\n",
      "‚úÖ Successfully connected to bucket: tech-translator-s3-knowledge-base\n",
      "üìÅ Bucket is empty\n",
      "üìÅ Created concepts/ directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Uploaded loss-ratio to s3://tech-translator-s3-knowledge-base/concepts/loss-ratio.json\n",
      "INFO:__main__:Uploaded predictive-model to s3://tech-translator-s3-knowledge-base/concepts/predictive-model.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Knowledge base concepts uploaded to existing bucket: tech-translator-s3-knowledge-base\n"
     ]
    }
   ],
   "source": [
    "# Initialize AWS clients\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Use your existing bucket\n",
    "BUCKET_NAME = \"tech-translator-s3-knowledge-base\"\n",
    "\n",
    "print(f\"Using existing S3 bucket: {BUCKET_NAME}\")\n",
    "\n",
    "# Check if bucket exists and is accessible\n",
    "try:\n",
    "    response = s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "    print(f\"‚úÖ Successfully connected to bucket: {BUCKET_NAME}\")\n",
    "    \n",
    "    # List existing objects\n",
    "    objects = s3.list_objects_v2(Bucket=BUCKET_NAME, MaxKeys=5)\n",
    "    if 'Contents' in objects:\n",
    "        print(f\"üìÅ Bucket contains {len(objects['Contents'])} objects (showing max 5):\")\n",
    "        for obj in objects['Contents'][:5]:\n",
    "            print(f\"  - {obj['Key']} ({obj['Size']} bytes)\")\n",
    "    else:\n",
    "        print(\"üìÅ Bucket is empty\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error accessing bucket: {str(e)}\")\n",
    "    print(\"Please check if the bucket exists and you have proper permissions\")\n",
    "    raise\n",
    "\n",
    "# Insurance data science concepts knowledge base\n",
    "concepts = [\n",
    "    {\n",
    "        \"concept_id\": \"r-squared\",\n",
    "        \"title\": \"R-squared\",\n",
    "        \"content\": {\n",
    "            \"definition\": \"R-squared (R¬≤) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by independent variables in a regression model.\",\n",
    "            \"technical_details\": \"R-squared values range from 0 to 1, where 0 indicates that the model explains none of the variability, and 1 indicates perfect prediction. It is calculated as 1 minus the ratio of the residual sum of squares to the total sum of squares.\",\n",
    "            \"insurance_context\": \"In insurance pricing, R-squared helps actuaries understand how well factors like age, location, or claim history explain premium variations. A high R-squared indicates that the selected rating factors are good predictors of risk.\",\n",
    "            \"limitations\": \"R-squared will always increase as more variables are added to a model, even if those variables are not significant. Adjusted R-squared addresses this limitation by penalizing the addition of variables that don't improve the model.\"\n",
    "        },\n",
    "        \"audience_explanations\": {\n",
    "            \"underwriter\": \"As an underwriter, you can think of R-squared as a measure of how well your pricing model captures risk factors. If your pricing model has an R-squared of 0.75, it means that 75% of the premium variation is explained by the factors in your model, while 25% remains unexplained. This unexplained portion might represent risk factors you're not capturing, which could lead to adverse selection if competitors have better models.\",\n",
    "            \"actuary\": \"When comparing generalized linear models (GLMs) for pricing, the model with higher R-squared (all else being equal) is explaining more of the variance in loss ratios across segments. However, be cautious of overfitting - a model with too many parameters might have a high R-squared on training data but perform poorly on new data. Cross-validation and consideration of information criteria like AIC and BIC are essential complements to R-squared evaluation.\",\n",
    "            \"executive\": \"R-squared provides a simple measure of how well our predictive models are working. An R-squared of 0.8 means our pricing model captures 80% of what drives premium differences, indicating a strong predictive model. The remaining 20% represents potential opportunity for competitive advantage if we can identify additional predictive factors that our competitors haven't discovered yet.\"\n",
    "        },\n",
    "        \"examples\": [\n",
    "            {\n",
    "                \"context\": \"Auto Insurance Pricing\",\n",
    "                \"explanation\": \"In an auto insurance pricing model, an R-squared of 0.72 indicates that factors like driver age, vehicle type, and prior claims explain 72% of the variation in claim costs across policyholders.\"\n",
    "            },\n",
    "            {\n",
    "                \"context\": \"Policy Renewal Prediction\",\n",
    "                \"explanation\": \"A customer retention model with an R-squared of 0.35 suggests that while you have some predictive power, much of what drives customers to renew or leave remains unexplained by your current variables.\"\n",
    "            }\n",
    "        ],\n",
    "        \"related_concepts\": [\"predictive modeling\", \"statistical significance\", \"p-value\", \"adjusted r-squared\"]\n",
    "    },\n",
    "    {\n",
    "        \"concept_id\": \"loss-ratio\",\n",
    "        \"title\": \"Loss Ratio\",\n",
    "        \"content\": {\n",
    "            \"definition\": \"Loss ratio is a key insurance metric that measures the relationship between incurred losses and earned premiums, expressed as a percentage.\",\n",
    "            \"technical_details\": \"The basic formula is: Loss Ratio = (Incurred Losses + Loss Adjustment Expenses) / Earned Premiums √ó 100%. A combined ratio additionally includes underwriting expenses and is calculated as Loss Ratio + Expense Ratio.\",\n",
    "            \"insurance_context\": \"Loss ratio is one of the most important profitability metrics in insurance. Generally, a loss ratio below 100% indicates underwriting profit (before considering investment income), while a ratio above 100% indicates an underwriting loss.\",\n",
    "            \"limitations\": \"Loss ratios can be volatile in the short term, especially for low-frequency, high-severity lines of business or for small portfolios. Loss ratios also don't account for the time value of money or investment income.\"\n",
    "        },\n",
    "        \"audience_explanations\": {\n",
    "            \"underwriter\": \"If you're seeing a loss ratio of 85% in a particular segment, it means that for every $100 in premium, $85 is being paid out in claims and claim expenses. This leaves only $15 for operational expenses, commissions, and profit. If your company's expense ratio is 20%, this segment is operating at a 5% loss. You may need to consider rate adjustments or tighter underwriting guidelines for this segment.\",\n",
    "            \"actuary\": \"When modeling loss ratios, we need to consider both frequency and severity trends, as well as large claim volatility and development patterns. A pure loss ratio that excludes IBNR and case reserve development can give a misleading picture of profitability. For long-tail lines, analyzing loss ratios by accident year versus calendar year can reveal important trends in ultimate loss expectations.\",\n",
    "            \"executive\": \"A loss ratio trend that increases from 60% to 70% over three quarters may signal emerging profitability challenges that require attention. With an expense ratio of 25%, this change would reduce your combined ratio from a profitable 85% to a borderline 95%, significantly impacting your underwriting margin. This trend could be due to inflation, changing risk profiles, competitor pricing actions, or claims handling efficiency.\"\n",
    "        },\n",
    "        \"examples\": [\n",
    "            {\n",
    "                \"context\": \"Property Insurance Performance\",\n",
    "                \"explanation\": \"A homeowners insurance portfolio with a 65% loss ratio and 30% expense ratio yields a combined ratio of 95%, indicating a 5% underwriting profit margin.\"\n",
    "            },\n",
    "            {\n",
    "                \"context\": \"Line of Business Comparison\",\n",
    "                \"explanation\": \"Commercial auto typically runs at higher loss ratios (around 75-80%) compared to commercial property (around 50-60%), which means pricing, underwriting, and reinsurance strategies need to be tailored differently for these lines.\"\n",
    "            }\n",
    "        ],\n",
    "        \"related_concepts\": [\"combined ratio\", \"expense ratio\", \"underwriting profit\", \"IBNR\", \"loss development\"]\n",
    "    },\n",
    "    {\n",
    "        \"concept_id\": \"predictive-model\",\n",
    "        \"title\": \"Predictive Model\",\n",
    "        \"content\": {\n",
    "            \"definition\": \"A predictive model is a statistical algorithm that uses historical data to predict future outcomes or classify new data points.\",\n",
    "            \"technical_details\": \"Common predictive modeling techniques include linear and logistic regression, decision trees, random forests, gradient boosting machines, neural networks, and ensemble methods. Models are evaluated using metrics like accuracy, precision, recall, F1-score, AUC-ROC, and mean squared error.\",\n",
    "            \"insurance_context\": \"In insurance, predictive models help estimate the likelihood of claims, premium adequacy, customer behavior, and fraud. They are used throughout the insurance lifecycle, from marketing and underwriting to claims management and renewal.\",\n",
    "            \"limitations\": \"Predictive models can only identify patterns present in historical data, may struggle with rare events, and can perpetuate historical biases if not carefully designed. They also require ongoing monitoring and retraining as conditions change.\"\n",
    "        },\n",
    "        \"audience_explanations\": {\n",
    "            \"underwriter\": \"The predictive model flags applications with risk scores based on patterns in historical data. For example, if an application scores in the highest risk decile, it has characteristics similar to policies that historically had 2.5 times more claims than average. These models don't replace your judgment - they provide an additional data point to complement your expertise, especially for factors that might not be obvious from traditional underwriting guidelines.\",\n",
    "            \"actuary\": \"When building predictive models for insurance applications, we need to balance predictive power with interpretability and regulatory compliance. A black-box model might achieve higher accuracy but could raise regulatory concerns about explainability. Generalized linear models (GLMs) remain popular in insurance because they provide a good balance of predictive power and interpretability, with clear indications of which factors drive predictions and by how much.\",\n",
    "            \"executive\": \"Our predictive models give us a competitive edge by identifying patterns that traditional approaches might miss. For example, our customer retention predictive model has improved retention by 5% by identifying at-risk policies before renewal, allowing targeted interventions. This translates to approximately $2M in saved premium that would otherwise have been lost, with minimal additional operational cost.\"\n",
    "        },\n",
    "        \"examples\": [\n",
    "            {\n",
    "                \"context\": \"Claims Triage\",\n",
    "                \"explanation\": \"A predictive model analyzes new claims and assigns each a complexity score from 1-10. Claims scoring 8+ are automatically routed to senior adjusters, while scores of 3 or below are fast-tracked for simple processing, optimizing adjuster workloads.\"\n",
    "            },\n",
    "            {\n",
    "                \"context\": \"Premium Leakage Detection\",\n",
    "                \"explanation\": \"A random forest model analyzes policy characteristics and identifies applications with a high probability of misclassification or missing information, flagging them for underwriter review before binding to prevent premium leakage.\"\n",
    "            }\n",
    "        ],\n",
    "        \"related_concepts\": [\"machine learning\", \"artificial intelligence\", \"data mining\", \"feature engineering\", \"model validation\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Upload concepts to existing bucket\n",
    "try:\n",
    "    # Check if concepts directory exists, create if not\n",
    "    try:\n",
    "        s3.head_object(Bucket=BUCKET_NAME, Key='concepts/')\n",
    "    except:\n",
    "        s3.put_object(Bucket=BUCKET_NAME, Key='concepts/', Body='')\n",
    "        print(\"üìÅ Created concepts/ directory\")\n",
    "    \n",
    "    # Upload each concept as a separate JSON file\n",
    "    for concept in concepts:\n",
    "        concept_id = concept[\"concept_id\"]\n",
    "        file_content = json.dumps(concept, indent=2)\n",
    "        key = f\"concepts/{concept_id}.json\"\n",
    "        \n",
    "        s3.put_object(\n",
    "            Bucket=BUCKET_NAME,\n",
    "            Key=key,\n",
    "            Body=file_content,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        logger.info(f\"Uploaded {concept_id} to s3://{BUCKET_NAME}/{key}\")\n",
    "    \n",
    "    print(f\"‚úÖ Knowledge base concepts uploaded to existing bucket: {BUCKET_NAME}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error uploading to existing bucket: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133d419-488a-47a6-82d5-d493edb53032",
   "metadata": {},
   "source": [
    "# Cell 3: Access to DynamoDB Vector Storage Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23224abb-b2fc-4f02-a57a-3c51e68d317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing DynamoDB table: tech-translator-dynamodb-vector-storage\n",
      "‚úÖ Successfully connected to table: tech-translator-dynamodb-vector-storage\n",
      "üìä Table Status: ACTIVE\n",
      "üìä Current Item Count: 0\n",
      "üîë Table Key Schema:\n",
      "  - concept_id (HASH)\n",
      "  - vector_id (RANGE)\n",
      "üìù Table is empty and ready for new embeddings\n",
      "üü¢ Table is ACTIVE and ready for read/write operations\n",
      "\n",
      "üìù Configuration:\n",
      "S3 Bucket: tech-translator-s3-knowledge-base\n",
      "DynamoDB Table: tech-translator-dynamodb-vector-storage\n",
      "Has Existing Data: False\n",
      "\n",
      "‚úÖ DynamoDB table verification complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize DynamoDB client and resource\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "\n",
    "# Use your existing table\n",
    "TABLE_NAME = \"tech-translator-dynamodb-vector-storage\"\n",
    "\n",
    "print(f\"Using existing DynamoDB table: {TABLE_NAME}\")\n",
    "\n",
    "# Check if table exists and is accessible\n",
    "try:\n",
    "    # Get table description\n",
    "    response = dynamodb.describe_table(TableName=TABLE_NAME)\n",
    "    table_status = response['Table']['TableStatus']\n",
    "    item_count = response['Table']['ItemCount']\n",
    "    \n",
    "    print(f\"‚úÖ Successfully connected to table: {TABLE_NAME}\")\n",
    "    print(f\"üìä Table Status: {table_status}\")\n",
    "    print(f\"üìä Current Item Count: {item_count}\")\n",
    "    \n",
    "    # Check table schema\n",
    "    key_schema = response['Table']['KeySchema']\n",
    "    print(\"üîë Table Key Schema:\")\n",
    "    for key in key_schema:\n",
    "        print(f\"  - {key['AttributeName']} ({key['KeyType']})\")\n",
    "    \n",
    "    # Check if table has any existing data\n",
    "    if item_count > 0:\n",
    "        print(f\"‚ö†Ô∏è  Table contains {item_count} existing items\")\n",
    "        \n",
    "        # Sample a few items to see what's there\n",
    "        table = dynamodb_resource.Table(TABLE_NAME)\n",
    "        sample_response = table.scan(Limit=3)\n",
    "        \n",
    "        if sample_response.get('Items'):\n",
    "            print(\"üìã Sample existing items:\")\n",
    "            for i, item in enumerate(sample_response['Items'][:3]):\n",
    "                print(f\"  {i+1}. concept_id: {item.get('concept_id', 'N/A')}, vector_id: {item.get('vector_id', 'N/A')}\")\n",
    "            \n",
    "            # Ask if user wants to clear existing data\n",
    "            print(\"\\nü§î Options for existing data:\")\n",
    "            print(\"1. Keep existing data and add new embeddings alongside\")\n",
    "            print(\"2. Clear existing data and start fresh\")\n",
    "            print(\"Note: We'll proceed with option 1 (keep existing data) by default\")\n",
    "            \n",
    "            # Set flag for later use\n",
    "            HAS_EXISTING_DATA = True\n",
    "        else:\n",
    "            HAS_EXISTING_DATA = False\n",
    "    else:\n",
    "        print(\"üìù Table is empty and ready for new embeddings\")\n",
    "        HAS_EXISTING_DATA = False\n",
    "    \n",
    "    # Verify table is ready for operations\n",
    "    if table_status == 'ACTIVE':\n",
    "        print(\"üü¢ Table is ACTIVE and ready for read/write operations\")\n",
    "    else:\n",
    "        print(f\"üü° Table status is {table_status} - waiting for it to become ACTIVE...\")\n",
    "        waiter = dynamodb.get_waiter('table_exists')\n",
    "        waiter.wait(TableName=TABLE_NAME)\n",
    "        print(\"üü¢ Table is now ACTIVE\")\n",
    "        \n",
    "except Exception as e:\n",
    "    if 'ResourceNotFoundException' in str(e):\n",
    "        print(f\"‚ùå Table {TABLE_NAME} does not exist!\")\n",
    "        print(\"Creating the table now...\")\n",
    "        \n",
    "        # Create the table if it doesn't exist\n",
    "        try:\n",
    "            dynamodb.create_table(\n",
    "                TableName=TABLE_NAME,\n",
    "                KeySchema=[\n",
    "                    {'AttributeName': 'concept_id', 'KeyType': 'HASH'},  # Partition key\n",
    "                    {'AttributeName': 'vector_id', 'KeyType': 'RANGE'}   # Sort key\n",
    "                ],\n",
    "                AttributeDefinitions=[\n",
    "                    {'AttributeName': 'concept_id', 'AttributeType': 'S'},\n",
    "                    {'AttributeName': 'vector_id', 'AttributeType': 'S'},\n",
    "                ],\n",
    "                BillingMode='PAY_PER_REQUEST'  # On-demand capacity\n",
    "            )\n",
    "            \n",
    "            # Wait for table to be created\n",
    "            print(f\"Creating table {TABLE_NAME}...\")\n",
    "            waiter = dynamodb.get_waiter('table_exists')\n",
    "            waiter.wait(TableName=TABLE_NAME)\n",
    "            print(f\"‚úÖ Table {TABLE_NAME} created successfully!\")\n",
    "            HAS_EXISTING_DATA = False\n",
    "            \n",
    "        except Exception as create_error:\n",
    "            print(f\"‚ùå Error creating table: {str(create_error)}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(f\"‚ùå Error accessing table: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Store these values for later use\n",
    "print(f\"\\nüìù Configuration:\")\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"DynamoDB Table: {TABLE_NAME}\")\n",
    "print(f\"Has Existing Data: {HAS_EXISTING_DATA if 'HAS_EXISTING_DATA' in locals() else False}\")\n",
    "\n",
    "print(f\"\\n‚úÖ DynamoDB table verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548dd68-3e01-4fe8-a144-9726452f3737",
   "metadata": {},
   "source": [
    "# Cell 4: Generate and Store Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12608f4-658b-4ae1-a326-e4da859d222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentence transformer model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d08850c4284dc5871becde0ac454ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3500c4d76bca4611a6fd7cdb0faaa05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee8797d6d643be88e2a8a6fb05d478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03ce8e19928470da93b8f8a0fae1ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa43a83b46064171a4b0ea4cc56a9dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f3b7160fad44b2bbd0435f78516a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c56f0d01588444bbf8cc597f0a2d108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da0ac35e0a9443fb572912dd19f1875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443e801d0cac4a809de1f525e5f901bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce2f4fb7cf24f58bb42b61a6230d8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3758cc443ab4d8ebff693d6f4e3e667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading concepts from s3://tech-translator-s3-knowledge-base/concepts/\n",
      "INFO:__main__:Loading concepts/loss-ratio.json\n",
      "INFO:__main__:Loaded concept: Loss Ratio\n",
      "INFO:__main__:Loading concepts/predictive-model.json\n",
      "INFO:__main__:Loaded concept: Predictive Model\n",
      "INFO:__main__:Loading concepts/r-squared.json\n",
      "INFO:__main__:Loaded concept: R-squared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RAG embedding generation process...\n",
      "Loaded 3 concepts\n",
      "Generated 24 text chunks\n",
      "Generating embeddings for 24 chunks...\n",
      "Processing chunk 1/24: loss-ratio-definition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b9362642ac440e8bd8d9572da8676d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-definition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 2/24: loss-ratio-technical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3051a3bbcc4002876827a9fb2d1219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-technical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 3/24: loss-ratio-context\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb11d04be1c4dbc8f3472f3ea48aa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 4/24: loss-ratio-underwriter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa504667b984dc7947fd8f0069b8693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-underwriter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 5/24: loss-ratio-actuary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79185d46457e4aafbf804423aaea5d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-actuary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 6/24: loss-ratio-executive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fffeb3fc61b401fa7055ced1838047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-executive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 7/24: loss-ratio-example-0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858a43bedda7417b8f9c65f554ba340f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-example-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 8/24: loss-ratio-example-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6951094117de4121b68f94ae094afdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for loss-ratio-example-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 9/24: predictive-model-definition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d1e67102ab4e6f9f4a902c9451a7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-definition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 10/24: predictive-model-technical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1151c80860ff41ecb2137763bfef68e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-technical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 11/24: predictive-model-context\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1d868150de45c78e12dc49ce618a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 12/24: predictive-model-underwriter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e546bfe254eb40a3a2f885321b9fc425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-underwriter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 13/24: predictive-model-actuary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381dbf9219f448a5b09e8fc01f2fda6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-actuary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 14/24: predictive-model-executive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2d296771db4348b1d3ae65abaec2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-executive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 15/24: predictive-model-example-0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9d06b1d3124e029eb2a8229dfb9fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-example-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 16/24: predictive-model-example-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf0515e011d4247b8731286569646d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for predictive-model-example-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 17/24: r-squared-definition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c690bbe8e29940d685f6b2dc3d014904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-definition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 18/24: r-squared-technical\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2377bb7b1489480ab3b52293e6807d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-technical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 19/24: r-squared-context\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1fcdab7c584fba955de859b520fdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 20/24: r-squared-underwriter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcc40ea75fc4799a6c2d978e7c3d835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-underwriter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 21/24: r-squared-actuary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b6d5e6701a47a38e527f0e851a3bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-actuary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 22/24: r-squared-executive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965eef3b61b14baba5c2331e3bd649d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-executive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 23/24: r-squared-example-0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f571663588c4fcd99d29f7b4d0173a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-example-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 24/24: r-squared-example-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0811ce9ff91b4da6bf482c75ec5fc8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored embedding for r-squared-example-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG embedding generation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize sentence transformer model and DynamoDB resource\n",
    "print(\"Loading sentence transformer model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "\n",
    "def load_concepts_from_s3(bucket_name):\n",
    "    \"\"\"Load all concept documents from S3\"\"\"\n",
    "    concepts = []\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Loading concepts from s3://{bucket_name}/concepts/\")\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix='concepts/')\n",
    "        \n",
    "        if 'Contents' not in response:\n",
    "            logger.warning(f\"No concept documents found\")\n",
    "            return concepts\n",
    "        \n",
    "        # Load each concept document\n",
    "        for obj in response['Contents']:\n",
    "            key = obj['Key']\n",
    "            if key.endswith('.json'):\n",
    "                logger.info(f\"Loading {key}\")\n",
    "                obj_response = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "                concept = json.loads(obj_response['Body'].read().decode('utf-8'))\n",
    "                concepts.append(concept)\n",
    "                logger.info(f\"Loaded concept: {concept['title']}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading concepts: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    return concepts\n",
    "\n",
    "def generate_chunks(concept):\n",
    "    \"\"\"Generate text chunks for each concept for embedding\"\"\"\n",
    "    chunks = []\n",
    "    concept_id = concept[\"concept_id\"]\n",
    "    title = concept[\"title\"]\n",
    "    \n",
    "    # Definition chunk\n",
    "    chunks.append({\n",
    "        \"concept_id\": concept_id,\n",
    "        \"vector_id\": f\"{concept_id}-definition\",\n",
    "        \"title\": title,\n",
    "        \"text\": concept[\"content\"][\"definition\"],\n",
    "        \"type\": \"definition\"\n",
    "    })\n",
    "    \n",
    "    # Technical details chunk\n",
    "    chunks.append({\n",
    "        \"concept_id\": concept_id,\n",
    "        \"vector_id\": f\"{concept_id}-technical\",\n",
    "        \"title\": title,\n",
    "        \"text\": concept[\"content\"][\"technical_details\"],\n",
    "        \"type\": \"technical\"\n",
    "    })\n",
    "    \n",
    "    # Insurance context chunk\n",
    "    chunks.append({\n",
    "        \"concept_id\": concept_id,\n",
    "        \"vector_id\": f\"{concept_id}-context\",\n",
    "        \"title\": title,\n",
    "        \"text\": concept[\"content\"][\"insurance_context\"],\n",
    "        \"type\": \"context\"\n",
    "    })\n",
    "    \n",
    "    # Audience-specific explanations\n",
    "    for audience, explanation in concept[\"audience_explanations\"].items():\n",
    "        chunks.append({\n",
    "            \"concept_id\": concept_id,\n",
    "            \"vector_id\": f\"{concept_id}-{audience}\",\n",
    "            \"title\": title,\n",
    "            \"text\": explanation,\n",
    "            \"type\": \"audience\",\n",
    "            \"audience\": audience\n",
    "        })\n",
    "    \n",
    "    # Examples\n",
    "    for i, example in enumerate(concept[\"examples\"]):\n",
    "        chunks.append({\n",
    "            \"concept_id\": concept_id,\n",
    "            \"vector_id\": f\"{concept_id}-example-{i}\",\n",
    "            \"title\": title,\n",
    "            \"text\": example[\"explanation\"],\n",
    "            \"type\": \"example\",\n",
    "            \"context\": example[\"context\"]\n",
    "        })\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def generate_and_store_embeddings(chunks, table_name):\n",
    "    \"\"\"Generate embeddings and store in DynamoDB\"\"\"\n",
    "    table = dynamodb_resource.Table(table_name)\n",
    "    \n",
    "    print(f\"Generating embeddings for {len(chunks)} chunks...\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}: {chunk['vector_id']}\")\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding = model.encode(chunk[\"text\"])\n",
    "        \n",
    "        # Prepare item for DynamoDB\n",
    "        item = {\n",
    "            \"concept_id\": chunk[\"concept_id\"],\n",
    "            \"vector_id\": chunk[\"vector_id\"],\n",
    "            \"title\": chunk[\"title\"],\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"type\": chunk[\"type\"],\n",
    "            \"embedding\": json.dumps(embedding.tolist())  # Store as JSON string\n",
    "        }\n",
    "        \n",
    "        # Add optional attributes\n",
    "        if \"audience\" in chunk:\n",
    "            item[\"audience\"] = chunk[\"audience\"]\n",
    "        if \"context\" in chunk:\n",
    "            item[\"context\"] = chunk[\"context\"]\n",
    "        \n",
    "        # Store in DynamoDB\n",
    "        try:\n",
    "            table.put_item(Item=item)\n",
    "            logger.info(f\"Stored embedding for {chunk['vector_id']}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error storing {chunk['vector_id']}: {str(e)}\")\n",
    "\n",
    "# Main embedding generation process\n",
    "print(\"Starting RAG embedding generation process...\")\n",
    "\n",
    "# Load concepts from S3\n",
    "concepts = load_concepts_from_s3(BUCKET_NAME)\n",
    "print(f\"Loaded {len(concepts)} concepts\")\n",
    "\n",
    "if concepts:\n",
    "    # Generate chunks\n",
    "    all_chunks = []\n",
    "    for concept in concepts:\n",
    "        chunks = generate_chunks(concept)\n",
    "        all_chunks.extend(chunks)\n",
    "    print(f\"Generated {len(all_chunks)} text chunks\")\n",
    "    \n",
    "    # Generate and store embeddings\n",
    "    generate_and_store_embeddings(all_chunks, TABLE_NAME)\n",
    "    \n",
    "    print(\"‚úÖ RAG embedding generation completed successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå No concepts loaded - check S3 bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae4f94-5d16-4f98-879b-c404ccca16e1",
   "metadata": {},
   "source": [
    "# Cell 5: Test Vector Search Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0bfa94f-da5d-475b-906f-fdfa07b7c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_concept_and_audience(query):\n",
    "    \"\"\"Extract concept and audience from user query\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Concept mapping\n",
    "    concept_keywords = {\n",
    "        'r-squared': ['r squared', 'r-squared', 'r2', 'coefficient of determination'],\n",
    "        'loss-ratio': ['loss ratio', 'claims ratio', 'incurred losses'],\n",
    "        'predictive-model': ['predictive model', 'prediction model', 'machine learning', 'ml model']\n",
    "    }\n",
    "    \n",
    "    detected_concept = None\n",
    "    for concept_id, keywords in concept_keywords.items():\n",
    "        if any(keyword in query_lower for keyword in keywords):\n",
    "            detected_concept = concept_id\n",
    "            break\n",
    "    \n",
    "    if not detected_concept:\n",
    "        detected_concept = 'predictive-model'  # Default\n",
    "    \n",
    "    # Audience mapping\n",
    "    audience_keywords = {\n",
    "        'underwriter': ['underwriter', 'underwriting'],\n",
    "        'actuary': ['actuary', 'actuarial', 'actuaries'],\n",
    "        'executive': ['executive', 'ceo', 'manager', 'leadership']\n",
    "    }\n",
    "    \n",
    "    detected_audience = None\n",
    "    for audience_id, keywords in audience_keywords.items():\n",
    "        if any(keyword in query_lower for keyword in keywords):\n",
    "            detected_audience = audience_id\n",
    "            break\n",
    "    \n",
    "    if not detected_audience:\n",
    "        detected_audience = 'general'\n",
    "    \n",
    "    return {'concept': detected_concept, 'audience': detected_audience}\n",
    "\n",
    "\n",
    "def vector_search(query, concept_id=None, top_k=5):\n",
    "    \"\"\"Perform vector search on stored embeddings\"\"\"\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    # Query DynamoDB\n",
    "    table = dynamodb_resource.Table(TABLE_NAME)\n",
    "    \n",
    "    if concept_id:\n",
    "        print(f\"üîç Searching in concept: {concept_id}\")\n",
    "        response = table.query(\n",
    "            KeyConditionExpression=\"concept_id = :concept_id\",\n",
    "            ExpressionAttributeValues={\":concept_id\": concept_id}\n",
    "        )\n",
    "    else:\n",
    "        print(\"üîç Searching across all concepts\")\n",
    "        response = table.scan()\n",
    "    \n",
    "    items = response.get('Items', [])\n",
    "    print(f\"Found {len(items)} items to search\")\n",
    "    \n",
    "    if not items:\n",
    "        return []\n",
    "    \n",
    "    # Calculate similarities\n",
    "    results = []\n",
    "    for item in items:\n",
    "        # Parse stored embedding\n",
    "        stored_embedding = json.loads(item['embedding'])\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity = 1 - cosine(query_embedding, stored_embedding)\n",
    "        \n",
    "        results.append({\n",
    "            'item': item,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    return results[:top_k]\n",
    "\n",
    "\n",
    "def generate_rag_response(query, search_results):\n",
    "    \"\"\"Generate response using retrieved information\"\"\"\n",
    "    if not search_results:\n",
    "        return \"I couldn't find relevant information for your query.\"\n",
    "    \n",
    "    # Get the best match\n",
    "    best_match = search_results[0]['item']\n",
    "    concept_title = best_match['title']\n",
    "    \n",
    "    # Build response using retrieved chunks\n",
    "    response_parts = [f\"# {concept_title} in Insurance\\n\"]\n",
    "    \n",
    "    # Add definition if available\n",
    "    definition_results = [r for r in search_results if r['item']['type'] == 'definition']\n",
    "    if definition_results:\n",
    "        response_parts.append(f\"## Definition\\n{definition_results[0]['item']['text']}\\n\")\n",
    "    \n",
    "    # Add insurance context\n",
    "    context_results = [r for r in search_results if r['item']['type'] == 'context']\n",
    "    if context_results:\n",
    "        response_parts.append(f\"## In Insurance\\n{context_results[0]['item']['text']}\\n\")\n",
    "    \n",
    "    # Add audience-specific explanation\n",
    "    audience_results = [r for r in search_results if r['item']['type'] == 'audience']\n",
    "    if audience_results:\n",
    "        audience = audience_results[0]['item'].get('audience', 'professional')\n",
    "        response_parts.append(f\"## For {audience.title()}s\\n{audience_results[0]['item']['text']}\\n\")\n",
    "    \n",
    "    # Add examples\n",
    "    example_results = [r for r in search_results if r['item']['type'] == 'example'][:2]\n",
    "    if example_results:\n",
    "        response_parts.append(\"## Examples\")\n",
    "        for example in example_results:\n",
    "            response_parts.append(f\"**{example['item'].get('context', 'Example')}**: {example['item']['text']}\")\n",
    "    \n",
    "    return \"\\n\".join(response_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74c57007-1127-4dc3-b4f2-d008806731bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Complete RAG System\n",
      "==================================================\n",
      "\n",
      "üí¨ Query: 'What is R-squared for an underwriter?'\n",
      "----------------------------------------\n",
      "üìä Extracted - Concept: r-squared, Audience: underwriter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e6c55b953b40dfadcfe50340f8e294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching in concept: r-squared\n",
      "Found 8 items to search\n",
      "üéØ Top matches (similarity scores):\n",
      "  1. [audience] r-squared-underwriter (0.727)\n",
      "  2. [definition] r-squared-definition (0.609)\n",
      "  3. [example] r-squared-example-0 (0.593)\n",
      "\n",
      "ü§ñ Generated Response:\n",
      "# R-squared in Insurance\n",
      "\n",
      "## Definition\n",
      "R-squared (R¬≤) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by independent variables in a regression model.\n",
      "\n",
      "## For Underwriters\n",
      "As an underwriter, you can think of R-squared as a measure of how well your pricing model captures risk factors. If your pricing model has an R-squared of 0.75, it means that 75% of the premium variation is explained by the factors in your model, while 25% remains unexplained. This unexplained portion might represent risk factors you're not capturing, which could lead to adverse selection if competitors have better models.\n",
      "\n",
      "## Examples\n",
      "**Auto Insurance Pricing**: In an auto insurance pricing model, an R-squared of 0.72 indicates that factors like driver age, vehicle type, and prior claims explain 72% of the variation in claim costs across policyholders.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí¨ Query: 'Explain loss ratio to an executive'\n",
      "----------------------------------------\n",
      "üìä Extracted - Concept: loss-ratio, Audience: executive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa6bb070b15415aaae71a260ff38b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching in concept: loss-ratio\n",
      "Found 8 items to search\n",
      "üéØ Top matches (similarity scores):\n",
      "  1. [definition] loss-ratio-definition (0.626)\n",
      "  2. [technical] loss-ratio-technical (0.619)\n",
      "  3. [context] loss-ratio-context (0.615)\n",
      "\n",
      "ü§ñ Generated Response:\n",
      "# Loss Ratio in Insurance\n",
      "\n",
      "## Definition\n",
      "Loss ratio is a key insurance metric that measures the relationship between incurred losses and earned premiums, expressed as a percentage.\n",
      "\n",
      "## In Insurance\n",
      "Loss ratio is one of the most important profitability metrics in insurance. Generally, a loss ratio below 100% indicates underwriting profit (before considering investment income), while a ratio above 100% indicates an underwriting loss.\n",
      "\n",
      "## For Underwriters\n",
      "If you're seeing a loss ratio of 85% in a particular segment, it means that for every $100 in premium, $85 is being paid out in claims and claim expenses. This leaves only $15 for operational expenses, commissions, and profit. If your company's expense ratio is 20%, this segment is operating at a 5% loss. You may need to consider rate adjustments or tighter underwriting guidelines for this segment.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí¨ Query: 'How do predictive models help actuaries?'\n",
      "----------------------------------------\n",
      "üìä Extracted - Concept: predictive-model, Audience: actuary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94fe6fae3374a738f98d55f4c4e2e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching in concept: predictive-model\n",
      "Found 8 items to search\n",
      "üéØ Top matches (similarity scores):\n",
      "  1. [context] predictive-model-context (0.602)\n",
      "  2. [definition] predictive-model-definition (0.559)\n",
      "  3. [audience] predictive-model-underwriter (0.526)\n",
      "\n",
      "ü§ñ Generated Response:\n",
      "# Predictive Model in Insurance\n",
      "\n",
      "## Definition\n",
      "A predictive model is a statistical algorithm that uses historical data to predict future outcomes or classify new data points.\n",
      "\n",
      "## In Insurance\n",
      "In insurance, predictive models help estimate the likelihood of claims, premium adequacy, customer behavior, and fraud. They are used throughout the insurance lifecycle, from marketing and underwriting to claims management and renewal.\n",
      "\n",
      "## For Underwriters\n",
      "The predictive model flags applications with risk scores based on patterns in historical data. For example, if an application scores in the highest risk decile, it has characteristics similar to policies that historically had 2.5 times more claims than average. These models don't replace your judgment - they provide an additional data point to complement your expertise, especially for factors that might not be obvious from traditional underwriting guidelines.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí¨ Query: 'Tell me about R-squared in simple terms'\n",
      "----------------------------------------\n",
      "üìä Extracted - Concept: r-squared, Audience: general\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5913c31a31f492799feee44f7b87c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching in concept: r-squared\n",
      "Found 8 items to search\n",
      "üéØ Top matches (similarity scores):\n",
      "  1. [definition] r-squared-definition (0.864)\n",
      "  2. [audience] r-squared-executive (0.738)\n",
      "  3. [technical] r-squared-technical (0.702)\n",
      "\n",
      "ü§ñ Generated Response:\n",
      "# R-squared in Insurance\n",
      "\n",
      "## Definition\n",
      "R-squared (R¬≤) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by independent variables in a regression model.\n",
      "\n",
      "## In Insurance\n",
      "In insurance pricing, R-squared helps actuaries understand how well factors like age, location, or claim history explain premium variations. A high R-squared indicates that the selected rating factors are good predictors of risk.\n",
      "\n",
      "## For Executives\n",
      "R-squared provides a simple measure of how well our predictive models are working. An R-squared of 0.8 means our pricing model captures 80% of what drives premium differences, indicating a strong predictive model. The remaining 20% represents potential opportunity for competitive advantage if we can identify additional predictive factors that our competitors haven't discovered yet.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ RAG System Testing Complete!\n"
     ]
    }
   ],
   "source": [
    "# Test the complete RAG system\n",
    "test_queries = [\n",
    "    \"What is R-squared for an underwriter?\",\n",
    "    \"Explain loss ratio to an executive\",\n",
    "    \"How do predictive models help actuaries?\",\n",
    "    \"Tell me about R-squared in simple terms\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Complete RAG System\\n\" + \"=\"*50)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüí¨ Query: '{query}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Extract concept and audience\n",
    "    extracted = extract_concept_and_audience(query)\n",
    "    print(f\"üìä Extracted - Concept: {extracted['concept']}, Audience: {extracted['audience']}\")\n",
    "    \n",
    "    # Perform vector search\n",
    "    search_results = vector_search(query, extracted['concept'])\n",
    "    \n",
    "    if search_results:\n",
    "        print(f\"üéØ Top matches (similarity scores):\")\n",
    "        for i, result in enumerate(search_results[:3]):\n",
    "            item = result['item']\n",
    "            print(f\"  {i+1}. [{item['type']}] {item['vector_id']} ({result['similarity']:.3f})\")\n",
    "        \n",
    "        # Generate RAG response\n",
    "        response = generate_rag_response(query, search_results)\n",
    "        print(f\"\\nü§ñ Generated Response:\\n{response}\")\n",
    "    else:\n",
    "        print(\"‚ùå No results found\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ RAG System Testing Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c0169-e3ba-47dc-bb19-557939208531",
   "metadata": {},
   "source": [
    "# Cell 6: Save Configuration for Lambda Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b004f4-3122-4a16-9c43-80d6bb282159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration for future reference\n",
    "config = {\n",
    "    \"bucket_name\": BUCKET_NAME,\n",
    "    \"table_name\": TABLE_NAME,\n",
    "    \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    \"region\": \"us-east-1\",\n",
    "    \"creation_timestamp\": int(time.time()),\n",
    "    \"concepts\": [concept[\"concept_id\"] for concept in concepts]\n",
    "}\n",
    "\n",
    "# Save configuration to S3\n",
    "config_content = json.dumps(config, indent=2)\n",
    "s3.put_object(\n",
    "    Bucket=BUCKET_NAME,\n",
    "    Key='rag_config.json',\n",
    "    Body=config_content,\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "print(\"üìã RAG Configuration Summary\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"S3 Bucket: {BUCKET_NAME}\")\n",
    "print(f\"DynamoDB Table: {TABLE_NAME}\")\n",
    "print(f\"Embedding Model: all-MiniLM-L6-v2\")\n",
    "print(f\"Concepts: {len(concepts)}\")\n",
    "print(f\"Total Chunks: {len(all_chunks)}\")\n",
    "print(\"\\n‚úÖ Configuration saved to S3 as 'rag_config.json'\")\n",
    "\n",
    "print(\"\\nüéâ RAG Implementation Complete!\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Deploy an open-source LLM (Phi-2 or Mistral-7B)\")\n",
    "print(\"2. Create Lambda functions for your API\")\n",
    "print(\"3. Connect the frontend to your RAG system\")\n",
    "print(\"4. Remember to STOP this SageMaker space when done to save costs!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
